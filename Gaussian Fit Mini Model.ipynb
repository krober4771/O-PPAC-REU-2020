{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first i need data from a previous run\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, metrics, Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from scipy.stats import truncnorm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import normalize\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import h5py\n",
    "import datetime\n",
    "from scipy.optimize import curve_fit\n",
    "import math\n",
    "from scipy import asarray as ar,exp\n",
    "import pylab as plb\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(\"/home/roberts/O-PPAC/recomplied_dataset.npy\")\n",
    "all_data = dataset[ : , :132]\n",
    "all_labels = dataset[: , -2:]\n",
    "\n",
    "print(all_data.shape)\n",
    "print(all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = normalize(all_data,axis = 1)\n",
    "print(np.max(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the test data as done above\n",
    "x1_data_all = (all_data[: , :33])\n",
    "x2_data_all = (all_data[:, 33:66])\n",
    "y1_data_all = (all_data[:, 66:99])\n",
    "y2_data_all = (all_data[:, 99:132])\n",
    "\n",
    "#labels kept so they have the same indices\n",
    "x_labels_all = all_labels[ : , 0 ]\n",
    "y_labels_all = all_labels[ : , 1 ]\n",
    "\n",
    "print(x1_data_all.shape)\n",
    "print(x_labels_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian fit function\n",
    "def gaussianpdf(x, k, sigma, mu):\n",
    "    return k*np.exp(-(x-mu)**2/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to (hopefully) fit gaussians (and thus, centroids which is what we want) onto all data sets\n",
    "def centroiddn(x, y):\n",
    "    try:\n",
    "        if np.max(y) > 20:\n",
    "            kvalue = np.max(y)+(np.max(y)/2)\n",
    "        elif np.max(y) == 0:\n",
    "            kvalue = 1\n",
    "        else:\n",
    "            kvalue = np.max(y)\n",
    "        popt, _ = curve_fit(gaussianpdf, x, y, bounds=(0, [kvalue,10., 33.]))\n",
    "        return popt[2]\n",
    "    except RuntimeError:\n",
    "        return -5555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_peaks(x_data, y_data):\n",
    "    fit_peaks = []\n",
    "    for i in tqdm(range(y_data.shape[0])):\n",
    "        fit_peaks.append(centroiddn(x_data, y_data[i,:]))\n",
    "    return np.array(fit_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peak_error(arr1data, arr2data):\n",
    "    error_indices1 = np.where(arr1data == -5555 )\n",
    "    error_indices2 = np.where(arr2data == -5555 )\n",
    "        \n",
    "    error_indices = np.unique(np.concatenate([error_indices1, error_indices2], axis = 1))\n",
    "        \n",
    "    return error_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_peak_error(arr1data, arr2data, removearr):\n",
    "    \n",
    "    arr1data_df = pd.DataFrame(arr1data)\n",
    "    arr2data_df = pd.DataFrame(arr2data)\n",
    "        \n",
    "    arr1data_df_fixed = arr1data_df.drop(arr1data_df.index[removearr])\n",
    "    arr2data_df_fixed = arr2data_df.drop(arr2data_df.index[removearr])\n",
    "        \n",
    "    arr1data_fixed = arr1data_df_fixed.to_numpy()\n",
    "    arr2data_fixed = arr2data_df_fixed.to_numpy()\n",
    "    \n",
    "    arr1data = np.reshape(arr1data_fixed, -1)\n",
    "    arr2data = np.reshape(arr2data_fixed, -1)\n",
    "    \n",
    "    return arr1data, arr2data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_label_indices(labels, indices):\n",
    "    labels = pd.DataFrame(labels)\n",
    "    labels_fixed = labels.drop(labels.index[indices])\n",
    "    labels = labels_fixed.to_numpy()\n",
    "    return np.reshape(labels, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversions from diode number to millimeters and vice versa\n",
    "#might need to be updated if Yassid sends a better method of converting\n",
    "def diodenum_to_mm(arr1data):\n",
    "    return (arr1data /33)*100 - 48\n",
    "\n",
    "def mm_to_diodenum(arr1data):\n",
    "    return ((arr1data + 48)/100)*33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(arr1data, arr2data):\n",
    "    avg = (arr1data + arr2data)/2\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_recompile(arr1, arr2, arrerror):\n",
    "    arr1, arr2 = remove_peak_error(arr1, arr2, arrerror)\n",
    "    avg_peaks = average(arr1, arr2)\n",
    "    mm_peaks = diodenum_to_mm(avg_peaks)\n",
    "    return avg_peaks, mm_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rangemin = 0\n",
    "rangemax = 200000\n",
    "\n",
    "ranges = (rangemin, rangemax)\n",
    "range_size = rangemax - rangemin\n",
    "\n",
    "x1_data = x1_data_all[rangemin:rangemax]\n",
    "x2_data = x2_data_all[rangemin:rangemax]\n",
    "y1_data = y1_data_all[rangemin:rangemax]\n",
    "y2_data = y2_data_all[rangemin:rangemax]\n",
    "\n",
    "x_labels = x_labels_all[rangemin:rangemax]\n",
    "y_labels = y_labels_all[rangemin:rangemax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_peaks = fit_peaks(np.arange(0,33,1), x1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"x1_peaks_file_2\", x1_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_peaks = fit_peaks(np.arange(0,33,1), x2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"x2_peaks_file_2\", x2_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_peaks = fit_peaks(np.arange(0,33,1), y1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"y1_peaks_file_2\", y1_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_peaks = fit_peaks(np.arange(0,33,1), y2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"y2_peaks_file_2\", y2_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data so I'm not running over the other kernels\n",
    "x1_peaks = np.load(\"x1_peaks_file_2.npy\")\n",
    "x2_peaks = np.load(\"x2_peaks_file_2.npy\")\n",
    "y1_peaks = np.load(\"y1_peaks_file_2.npy\")\n",
    "y2_peaks = np.load(\"y2_peaks_file_2.npy\")\n",
    "\n",
    "print(len(x1_peaks))\n",
    "print(len(x2_peaks))\n",
    "print(len(y1_peaks))\n",
    "print(len(y2_peaks))\n",
    "\n",
    "print(x1_peaks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x1_data[46277])\n",
    "plt.axvline(x = x1_peaks[46277])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_errors = find_peak_error(x1_peaks, x2_peaks)\n",
    "y_errors = find_peak_error(y1_peaks, y2_peaks)\n",
    "\n",
    "all_error_indices = np.unique(np.concatenate([x_errors, y_errors]))\n",
    "\n",
    "all_error_indices = np.array(all_error_indices)\n",
    "np.save(\"all_error_indices\", all_error_indices)\n",
    "print(all_error_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_peaks, x_peaks_mm = peak_recompile(x1_peaks, x2_peaks, all_error_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_peaks, y_peaks_mm = peak_recompile(y1_peaks, y2_peaks, all_error_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = remove_label_indices(x_labels, all_error_indices)\n",
    "y_labels = remove_label_indices(y_labels, all_error_indices)\n",
    "\n",
    "print(x_labels.shape)\n",
    "print(x_peaks_mm.shape)\n",
    "print(y_labels.shape)\n",
    "print(y_peaks_mm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph showing the accuracy of gaussian fit by comparing predicted and true x values\n",
    "#should be as close to the diagonal as possible\n",
    "a = plt.axes(aspect='equal')\n",
    "\n",
    "plt.scatter(x_labels, x_pea, s=6, marker = \"x\")\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "lims = [-50, 50]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims, linewidth = .5)\n",
    "plt.title(\"Gaussian Fit O-PPAC X Predictions vs True X Values (events %5.0f - %5.0f)\" %tuple(ranges))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#to find the locations of largest error within my predicted x values\n",
    "x_error = np.abs(x_peaks_mm - x_labels)\n",
    "\n",
    "print(x_error.shape)\n",
    "\n",
    "problem_indices_x = [idx for (idx, err) in enumerate(x_error) if err >= 10]\n",
    "print(len(problem_indices_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k= 46277\n",
    "\n",
    "print(x_peaks_mm[k])\n",
    "print(mm_to_diodenum(x_peaks_mm[k]))\n",
    "print(x_labels[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5 #choose the index of the error (above)\n",
    "true_x = mm_to_diodenum(x_labels[problem_indices_x[i]])\n",
    "\n",
    "plt.title('Problem Location Example (index = %5.0f)' %(problem_indices_x[i]+rangemin))\n",
    "plt.plot(x1_data_all[problem_indices_x[i] + rangemin], linewidth = 2, label = \"data\")\n",
    "plt.axvline(x = x_peaks[problem_indices_x[i]], color = \"red\", linestyle=\":\",label = \"fit peak = %5.1f\" %x_peaks[problem_indices_x[i]])\n",
    "plt.axvline(x = x1_peaks[problem_indices_x[i]], color = \"black\", linewidth = 1, linestyle=\":\", label = \"x1 fit peak = %5.1f\" % x1_peaks[problem_indices_x[i]])\n",
    "plt.axvline(x = x2_peaks[problem_indices_x[i]], color = \"magenta\", linewidth = 1, linestyle=\":\", label = \"x2 fit peak = %5.1f\" % x2_peaks[problem_indices_x[i]])\n",
    "plt.axvline(x = true_x, color = \"green\", linestyle=\":\",label = \"true peak = %5.1f\" %true_x)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph showing the accuracy of gaussian fit by comparing predicted and true y values\n",
    "#should be as close to the diagonal as possible\n",
    "a = plt.axes(aspect='equal')\n",
    "\n",
    "plt.scatter(y_labels, y_peaks_mm, s=6, marker = \"x\")\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "lims = [-50, 50]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims, linewidth = .5)\n",
    "plt.title(\"Gaussian Fit O-PPAC Y Predictions vs True Y Values (events %5.0f - %5.0f)\" %tuple(ranges))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the locations of largest error within my predicted x values\n",
    "y_error = np.abs(y_peaks_mm - y_labels)\n",
    "\n",
    "print(y_error.shape)\n",
    "\n",
    "problem_indices_y = [idx for (idx, err) in enumerate(y_error) if err >= 10]\n",
    "print(problem_indices_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph locations of large y error\n",
    "i = 0 #choose the index of the error (above)\n",
    "\n",
    "plt.title('Problem Location Example')\n",
    "plt.plot(y1_data_all[5125 + rangemin])\n",
    "plt.axvline(x = y1_peaks[problem_indices_y[i]], color = \"red\")\n",
    "plt.axvline(x = y_labels[problem_indices_y[i]], color = \"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic gaussian fit stuff; needs x and y inputs for all data points; index is both for the y data and for lower code\n",
    "index = 138450\n",
    "x = np.arange(0,33,1)\n",
    "y = x1_data[index,:]\n",
    "\n",
    "print(y)\n",
    "x_labels_index = range_size - (rangemax - index)\n",
    "\n",
    "#the true location of the peak as given by the label for that event\n",
    "x_peak_true_value = ((x_labels[x_labels_index]+48)/100)*33\n",
    "x_peak_fit_value = x_peaks[x_labels_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curve fit code; bounds might be able to be played with still to improve model (specifically sigma in index 1)\n",
    "#trying new stuff to better balance k based on the input data\n",
    "if np.max(y) > 20:\n",
    "    kvalue = np.max(y)+(np.max(y)/2)\n",
    "elif np.max(y) == 0:\n",
    "    kvalue = 1\n",
    "else:\n",
    "    kvalue = np.max(y)\n",
    "\n",
    "popt, _ = curve_fit(gaussianpdf, x, y, bounds=(0, [kvalue,10., 33.]))\n",
    "print(popt[2])\n",
    "print(x_peak_true_value)\n",
    "print(x_peak_fit_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting gaussian to make sure it looks logically correct\n",
    "plt.plot(x, gaussianpdf(x, *popt), 'g--', label='fit: k=%5.3f, sigma=%5.3f, mu=%5.3f' % tuple(popt))\n",
    "plt.plot(x1_data[index,:], label = \"data\")\n",
    "plt.axvline(x = x_peak_fit_value, color = \"black\", linewidth=.4, label='Pred Peak= %5.1f' %x_peak_fit_value)\n",
    "plt.axvline(x = x_peak_true_value, color = \"magenta\", linewidth=1, label='True Peak= %5.1f' % x_peak_true_value)\n",
    "plt.axvline(x = popt[2], color = \"red\", linewidth=.4, linestyle='dashdot', label='Fit Peak= %5.1f' %popt[2])\n",
    "plt.title('Event Number %5.0f' %index)\n",
    "plt.xlabel('Diode Number')\n",
    "plt.ylabel('Number of Detected Photons')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
