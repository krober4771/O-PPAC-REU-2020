{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "import Preprocessing #my module\n",
    "from Preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(991, 342, 132)\n"
     ]
    }
   ],
   "source": [
    "dataset = h5py.File(\"/home/roberts/O-PPAC/simu_HDF_thistimeforReal.h5\", 'r') #load data\n",
    "num_diodes = dataset['Num_diodes'][...] #separate the data into each key within the data file\n",
    "x_pos = (dataset['Xpos'][...])/100 #puts the scale into mm\n",
    "y_pos = (dataset['Ypos'][...])/100\n",
    "histgrid = dataset['histgrid'][...]\n",
    "histgrid = histgrid[:-10,:,:] #redefine the shape and size of histgrid by removing the last 10 events (they are bad)\n",
    "output = np.vstack((x_pos,y_pos)) #define new, single variable for x and y position\n",
    "output = np.transpose(output) #original definition was sideways, so we transposed it\n",
    "\n",
    "print(histgrid.shape)\n",
    "\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure there are no NaNs (FCNN gets angry when NaNs)\n",
    "assert not(np.any(np.isnan(histgrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(338922, 132)\n",
      "(338922, 2)\n"
     ]
    }
   ],
   "source": [
    "all_data, all_labels = data_compile(histgrid, output)\n",
    "\n",
    "#to make sure everything is the correct shape\n",
    "print(all_data.shape)\n",
    "print(all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8395246220687987\n"
     ]
    }
   ],
   "source": [
    "all_data = normalize(all_data,axis = 1)\n",
    "print(np.max(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define all_labels and all_data as df's to better view rows and add column\n",
    "all_labels = pd.DataFrame(all_labels)\n",
    "all_data = pd.DataFrame(all_data)\n",
    "all_data[\"sum\"] = np.sum(all_data, axis = 1) #column added to find rows with only 0's\n",
    "\n",
    "#confirming number of initial entries\n",
    "print(len(all_labels))\n",
    "print(len(all_data))\n",
    "\n",
    "#find all the locations in all_data (by index) where the only values are 0 across the diodes\n",
    "remove_labels = list(all_data[all_data[\"sum\"] == 0].index)\n",
    "print(len(remove_labels))\n",
    "\n",
    "#added these to ensure I have unshuffled versions of the data and labels for finding locations with larger error\n",
    "unshuf_labels = all_labels.drop(all_labels.index[remove_labels])\n",
    "unshuf_data = all_data[all_data[\"sum\"] != 0]\n",
    "\n",
    "#lets all_labels and all_data start with the same indices and values as their unshuffled counterparts\n",
    "all_labels = unshuf_labels\n",
    "unshuf_labels = unshuf_labels.to_numpy() #dfs are hard to graph with, so I converted to np.arrays for future use\n",
    "all_data = unshuf_data\n",
    "unshuf_data = unshuf_data.to_numpy()\n",
    "\n",
    "#confirm new number of entries (should be len(remove_labels) less than the intital value)\n",
    "print(len(all_labels))\n",
    "print(len(all_data))\n",
    "\n",
    "#must remove the sum column before using in FCNN; otherwise it will treat it as a data point \n",
    "del all_data['sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate((all_data, all_labels), axis=1)\n",
    "#puts the x,y labels at the end of each data row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)  #confirm it is the correct shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"recomplied_dataset_fixed\" , dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure it works\n",
    "new_dataset = np.load(\"/home/roberts/O-PPAC/recomplied_dataset_fixed.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
